{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection with BG_SubtractorMOG2: (Research Part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a Video:\n",
    "cap = cv2.VideoCapture('C:/Users/subha/Desktop/Research Contracts!/Vehicle Detection & Tracking!/VDT!/Car-1!.mp4')\n",
    "\n",
    "# You can optionally work on the live web cam\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create the Background Object, you can choose to detect shadows or not: (if True they will be shown as gray)\n",
    "backgroundobject = cv2.createBackgroundSubtractorMOG2( history = 2, detectShadows = True )\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()  \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Apply the background object on each frame:\n",
    "    fgmask = backgroundobject.apply(frame)\n",
    "\n",
    "    # Also extracting the real detected foreground part of the image (optional):\n",
    "    real_part = cv2.bitwise_and(frame,frame,mask=fgmask)\n",
    "    \n",
    "    # Making fgmask 3 channeled so it can be stacked with others:\n",
    "    fgmask_3 = cv2.cvtColor(fgmask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Stack all three frames and show the image:\n",
    "    stacked = np.hstack((fgmask_3, frame, real_part))\n",
    "    cv2.imshow('Sample',cv2.resize(stacked, None, fx=0.65, fy=0.65))\n",
    " \n",
    "    k = cv2.waitKey(30) &  0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "   \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a video:\n",
    "video = cv2.VideoCapture('C:/Users/subha/Desktop/Research Contracts!/Vehicle Detection & Tracking!/VDT!/Car-1!.mp4')\n",
    "\n",
    "# You can set custom kernel size if you want:\n",
    "kernel = None\n",
    "\n",
    "# Initialize the background object:\n",
    "backgroundObject = cv2.createBackgroundSubtractorMOG2(detectShadows = False)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read a new frame:\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Check if frame is not read correctly:\n",
    "    if not ret:\n",
    "        \n",
    "        # Break the loop:\n",
    "\n",
    "        break\n",
    "\n",
    "    # Apply the background object on the frame to get the segmented mask: \n",
    "    fgmask = backgroundObject.apply(frame)\n",
    "    #initialMask = fgmask.copy()\n",
    "    \n",
    "    # Perform thresholding to get rid of the shadows:\n",
    "    _, fgmask = cv2.threshold(fgmask, 250, 255, cv2.THRESH_BINARY)\n",
    "    #noisymask = fgmask.copy()\n",
    "    \n",
    "    # Apply some morphological operations to make sure you have a good mask:\n",
    "    fgmask = cv2.erode(fgmask, kernel, iterations = 1)\n",
    "    fgmask = cv2.dilate(fgmask, kernel, iterations = 2)\n",
    "    \n",
    "    # Detect contours in the frame:\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create a copy of the frame to draw bounding boxes around the detected cars:\n",
    "    frameCopy = frame.copy()\n",
    "    \n",
    "    # loop over each contour found in the frame:\n",
    "    for cnt in contours:\n",
    "        \n",
    "        # Make sure the contour area is somewhat higher than some threshold to make sure its a car and not some noise:\n",
    "        if cv2.contourArea(cnt) > 400:\n",
    "            \n",
    "            # Retrieve the bounding box coordinates from the contour:\n",
    "            x, y, width, height = cv2.boundingRect(cnt)\n",
    "            \n",
    "            # Draw a bounding box around the Bike:\n",
    "            cv2.rectangle(frameCopy, (x , y), (x + width, y + height),(0, 0, 255), 2)\n",
    "            \n",
    "            # Write Bike Detected near the bounding box drawn:\n",
    "            cv2.putText(frameCopy, 'Car Detected', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,255,0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    # Extract the foreground from the frame using the segmented mask:\n",
    "    foregroundPart = cv2.bitwise_and(frame, frame, mask=fgmask)\n",
    "        \n",
    "    # Stack the original frame, extracted foreground, and annotated frame:\n",
    "    stacked = np.hstack((frame, foregroundPart))\n",
    "\n",
    "    # Display the stacked image with an appropriate title.\n",
    "    cv2.imshow('Original Frame, Extracted Foreground and Detected Cars', cv2.resize(stacked, None, fx=0.5, fy=0.5))\n",
    "    #cv2.imshow('initial Mask', initialMask)\n",
    "    #cv2.imshow('Noisy Mask', noisymask)\n",
    "    #cv2.imshow('Clean Mask', fgmask)\n",
    "\n",
    "\n",
    "    # Wait until a key is pressed.\n",
    "    # Retreive the ASCII code of the key pressed\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    \n",
    "    # Check if 'q' key is pressed.\n",
    "    if k == ord('q'):\n",
    "        \n",
    "        # Break the loop.\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture Object.\n",
    "video.release()\n",
    "\n",
    "# Close the windows.q\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Counter with Background_SubtractorMOG2: (Project Part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\subha\\anaconda3\\lib\\site-packages (4.5.1.48)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\subha\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle Counter:1\n",
      "Vehicle Counter:2\n",
      "Vehicle Counter:3\n",
      "Vehicle Counter:4\n",
      "Vehicle Counter:5\n",
      "Vehicle Counter:6\n",
      "Vehicle Counter:7\n",
      "Vehicle Counter:8\n",
      "Vehicle Counter:9\n",
      "Vehicle Counter:10\n",
      "Vehicle Counter:11\n",
      "Vehicle Counter:12\n",
      "Vehicle Counter:13\n",
      "Vehicle Counter:14\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load Video:\n",
    "cap = cv2.VideoCapture('C:/Users/subha/Desktop/Research Contracts!/Vehicle Detection & Tracking!/VDT!/Car-1!.mp4')\n",
    "\n",
    "# Declaring Rectangle Dimensions:\n",
    "\n",
    "min_width_react = 80\n",
    "min_height_react = 80\n",
    "count_line_position = 550\n",
    "\n",
    "# Innitialize Subtractor:\n",
    "\n",
    "algo = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "def center_handle(x,y,w,h):\n",
    "    x1=int(w/2)\n",
    "    y1=int(h/2)\n",
    "    cx = x+x1\n",
    "    cy = y+y1\n",
    "    return cx, cy\n",
    "detect = []\n",
    "offset = 5 # Allowable Error Between Pixels\n",
    "counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap.read()\n",
    "    grey = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(grey, (3, 3), 5)\n",
    "    \n",
    "    # Applying on each Frame:\n",
    "    img_sub = algo.apply(blur)\n",
    "    dilat = cv2.dilate(img_sub, np.ones((1,1)))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1,1))\n",
    "    dilatada = cv2.morphologyEx(dilat, cv2.MORPH_CLOSE, kernel)\n",
    "    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)\n",
    "    contourShape,h = cv2.findContours(dilatada, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cv2.line(frame1, (25, count_line_position),(1200, count_line_position), (255,127,0), 3)\n",
    "    \n",
    "    \n",
    "    for (i,c) in enumerate(contourShape):\n",
    "        (x,y,w,h) = cv2.boundingRect(c)\n",
    "        validate_counter = (w>= min_width_react) and (h>= min_height_react)\n",
    "        if not validate_counter:\n",
    "            continue\n",
    "            \n",
    "        cv2.rectangle(frame1, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "        cv2.putText(frame1, \"Vehicle\"+str(counter), (x, y - 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,244,255),5)\n",
    "        \n",
    "        center = center_handle(x,y,w,h)\n",
    "        detect.append(center)\n",
    "        cv2.circle(frame1, center, 4, (0,0,255), -1)\n",
    "        \n",
    "        for (x,y) in detect:\n",
    "            if y<(count_line_position+offset) and y>(count_line_position-offset):\n",
    "                counter+=1\n",
    "                cv2.line(frame1, (25, count_line_position),(1200, count_line_position), (0,127,255), 3)\n",
    "                detect.remove((x,y))\n",
    "                print(\"Vehicle Counter:\"+str(counter))\n",
    "        \n",
    "    cv2.putText(frame1, \"Vehicle Counter:\"+str(counter), (450, 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255),5)\n",
    "            \n",
    "    \n",
    "#     cv2.imshow('Detector', dilatada)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('Original Video', frame1)\n",
    "    \n",
    "    \n",
    "    # Retreive the ASCII code of the key pressed\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    \n",
    "    # Check if 'q' key is pressed.\n",
    "    if k == ord('q'):\n",
    "        \n",
    "        # Break the loop.\n",
    "        break\n",
    "\n",
    "# Close the windows.q\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle Counter:1\n",
      "Vehicle Counter:2\n",
      "Vehicle Counter:3\n",
      "Vehicle Counter:4\n",
      "Vehicle Counter:5\n",
      "Vehicle Counter:6\n",
      "Vehicle Counter:7\n",
      "Vehicle Counter:8\n",
      "Vehicle Counter:9\n",
      "Vehicle Counter:10\n",
      "Vehicle Counter:11\n",
      "Vehicle Counter:12\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load Video:\n",
    "cap = cv2.VideoCapture('C:/Users/subha/Desktop/Research Contracts!/Vehicle Detection & Tracking!/VDT!/Car-1!.mp4')\n",
    "fps_start_time = 0\n",
    "fps = 0\n",
    "\n",
    "# Declaring Rectangle Dimensions:\n",
    "min_width_react = 80\n",
    "min_height_react = 80\n",
    "count_line_position = 550\n",
    "\n",
    "# Innitialize Subtractor:\n",
    "algo = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "def center_handle(x,y,w,h):\n",
    "    x1=int(w/2)\n",
    "    y1=int(h/2)\n",
    "    cx = x+x1\n",
    "    cy = y+y1\n",
    "    return cx, cy\n",
    "detect = []\n",
    "offset = 5 # Allowable Error Between Pixels\n",
    "counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap.read()\n",
    "    \n",
    "    # FPS Calculator:\n",
    "    fps_end_time = time.time()\n",
    "    time_diff = fps_end_time - fps_start_time\n",
    "    fps = 1/(time_diff)\n",
    "    fps_start_time = fps_end_time\n",
    "    fps_text = \"FPS: {:.2f}\".format(fps)\n",
    "    cv2.putText(frame1, fps_text, (5, 30), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,0),2)\n",
    "    \n",
    "    \n",
    "    grey = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(grey, (3, 3), 5)\n",
    "    \n",
    "    # Applying on each Frame:\n",
    "    img_sub = algo.apply(blur)\n",
    "    dilat = cv2.dilate(img_sub, np.ones((1,1)))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1,1))\n",
    "    dilatada = cv2.morphologyEx(dilat, cv2.MORPH_CLOSE, kernel)\n",
    "    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)\n",
    "    contourShape,h = cv2.findContours(dilatada, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cv2.line(frame1, (25, count_line_position),(1200, count_line_position), (0,0,0), 2)\n",
    "    \n",
    "    # Vehicle Counter:\n",
    "    for (i,c) in enumerate(contourShape):\n",
    "        (x,y,w,h) = cv2.boundingRect(c)\n",
    "        validate_counter = (w>= min_width_react) and (h>= min_height_react)\n",
    "        if not validate_counter:\n",
    "            continue\n",
    "            \n",
    "        cv2.rectangle(frame1, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "        cv2.putText(frame1, \"Vehicle\"+str(counter), (x, y - 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)\n",
    "        \n",
    "        center = center_handle(x,y,w,h)\n",
    "        detect.append(center)\n",
    "        cv2.circle(frame1, center, 4, (0,0,255), -1)\n",
    "        \n",
    "        for (x,y) in detect:\n",
    "            if y<(count_line_position+offset) and y>(count_line_position-offset):\n",
    "                counter+=1\n",
    "                cv2.line(frame1, (25, count_line_position),(1200, count_line_position), (0,0,0), 2)\n",
    "                detect.remove((x,y))\n",
    "                print(\"Vehicle Counter:\"+str(counter))\n",
    "        \n",
    "    cv2.putText(frame1, \"Vehicle Counter:\"+str(counter), (450, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),3)\n",
    "            \n",
    "    \n",
    "#     cv2.imshow('Detector', dilatada)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('Original Video', frame1)\n",
    "    \n",
    "    \n",
    "    # Retreive the ASCII code of the key pressed\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    \n",
    "    # Check if 'q' key is pressed.\n",
    "    if k == ord('q'):\n",
    "        \n",
    "        # Break the loop:\n",
    "        break\n",
    "\n",
    "# Close the windows.q\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
